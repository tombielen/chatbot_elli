# Elli: AI-Powered Chatbot for Mental Health Screening

This repository contains **Elli**, a GPT-4-powered mental health chatbot developed by **Tom Bielen** as part of his independent bachelorâ€™s thesis research in Applied Psychology at IU International University of Applied Sciences.

**Elli** is designed to conduct **empathetic, conversational mental health screenings** using validated tools like the **PHQ-9** and **GAD-7**, while measuring user trust, comfort, emotional response, and interaction patterns.

> âš ï¸ **Disclaimer:**  
> Elli is a research prototype. It is **not** intended for clinical use, diagnosis, or emergency mental health support.  
> If you or someone you know is struggling, please contact a licensed professional or local helpline.

---

## ðŸ§  Research Background

**Initial Research Question:**  
> _Can an AI-powered chatbot effectively and empathetically conduct mental health screening using validated psychometric tools such as GAD-7 and PHQ-9?_

### Thesis Title  
**Redefining Digital Therapeutic Alliance: A Multidimensional Model of Empathy, Trust, and Bias in LLM-Powered Mental Health Screening**

The study investigates how conversational empathy and relational dynamics in large language models (LLMs) influence psychological processes such as trust, self-disclosure, and screening accuracy, compared to static digital forms.

---

## ðŸ§ª Study Design

- **Participants:** 120+ English-speaking adults (18+)
- **Conditions:**
  - **Elli Chatbot:** GPT-4 powered, adaptive, empathic
  - **Static Web Form:** Control condition, no empathy or interactivity
- **Measures Collected:**
  - PHQ-9, GAD-7 scores
  - Trust, comfort, empathy perception
  - System Usability Scale (SUS)
  - Behavioral metrics (completion time, dropout, disclosure depth)
  - Open-ended feedback (privacy, emotional experience)