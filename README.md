# Elli: AI-Powered Chatbot for Mental Health Screening

This repository contains Elli, a GPT-4-powered mental health chatbot developed by Tom Bielen as part of an independent research project. 

Elli is designed to conduct empathetic, conversational mental health screenings using validated tools like the PHQ-9 and GAD-7, while measuring user trust, comfort, emotional response, and interaction patterns.

> ‚ö†Ô∏è **Disclaimer:**  
> Elli is a research prototype. It is not intended for clinical use, diagnosis, or emergency mental health support.  
> If you or someone you know is struggling, please contact a licensed professional or local helpline.

---

## üß† Research Background

**Initial Research Question:**  
> _Can an AI-powered chatbot effectively and empathetically conduct mental health screening using validated psychometric tools such as GAD-7 and PHQ-9?_

### Thesis Title  
**Redefining Digital Therapeutic Alliance: A Multidimensional Model of Empathy, Trust, and Bias in LLM-Powered Mental Health Screening**

The study investigates how conversational empathy and relational dynamics in large language models (LLMs) influence psychological processes such as trust, self-disclosure, and screening accuracy, compared to static digital forms.

---

## üß™ Study Design

- **Participants:** 100+ English-speaking adults (18+)
- **Conditions:**
  - **Elli Chatbot:** GPT-4 powered, adaptive, empathic
  - **Static Web Form:** Control condition, no empathy or interactivity
- **Measures Collected:**
  - PHQ-9, GAD-7 scores
  - Trust, comfort, empathy perception
  - Behavioral metrics (completion time, dropout, disclosure depth)
  - Open-ended feedback (privacy, emotional experience)

---

## üéØ Research Objectives

1. **Model Development:** Create a multidimensional framework linking empathy, trust, and bias in AI mental health screening.
2. **Experimental Evaluation:** Compare Elli against a static form using randomized assignment.
3. **Mechanistic Analysis:** Analyze how empathy and interactivity affect trust, disclosure, and diagnostic outcomes.
4. **Bias Forensics:** Audit for demographic and linguistic bias in screening results and user feedback.
5. **Ethical Implications:** Inform policy and design recommendations for responsible LLM integration in mental health tools.

---

## üß™ Methodology Overview

- **Design:** Randomized, cross-sectional, mixed-methods.
- **Conditions:** Participants are assigned to either Elli (empathic chatbot) or a static, neutral web form.
- **Platform:** Built with Streamlit and hosted on a secure, GDPR-compliant server.
- **Data:** Responses are anonymized, encrypted, and stored with strict access control.
- **Instruments:** PHQ-9, GAD-7, trust and empathy scales, behavioral logs, and open-ended feedback.

---

## üîê Ethics and Privacy

- Informed consent is required before participation.
- Participants experiencing acute distress are referred to support resources.
- All data are anonymized and stored in encrypted, GDPR-compliant systems.
- Elli‚Äôs limitations as a non-clinical tool are clearly communicated to users.